#!/usr/bin/env python
# -*- coding: utf-8 -*-

#
# extract_feedback.py
#
# Copyright (C) 2015 Kano Computing Ltd.
# License: http://www.gnu.org/licenses/gpl-2.0.txt GNU General Public License v2
#
# This script extracts log files from a html page generated by drfeedback.py
# for automated analysis. Individual kano-logs


import sys
import os
from BeautifulSoup import BeautifulSoup as BS
from docopt import docopt
import json

doc = """
    Usage:
      python extract-feedback.py <file.html> <dest>
"""

args = docopt(doc)
filename = args['<file.html>']

with open(filename) as f:
        data = f.read()

soup = BS(data)

h3s = soup.findAll('h3')

os.system('mkdir -p {}'.format(args['<dest>']))
os.system('mkdir -p {}/.kano-logs'.format(args['<dest>']))

for h3 in h3s:
    s = h3.findNextSibling()
    if s.get('class') == u'logfile':
        x = h3.text.split(': ')
        print x
        (prefix, dump_filename) = x
        if dump_filename == u'app-logs-json.txt':
                js = json.loads(s.text)
                for logname in js.keys():
                        appname = os.path.basename(logname)
                        outname = os.path.join(args['<dest>'],
                                               '.kano-logs', appname)
                        with open(outname, 'w') as of:
                            for item in js[logname]:
                                json.dump(item, of)
                                of.write('\n')
        else:
                with open(os.path.join(args['<dest>'],
                                       dump_filename), 'w') as of:
                        of.write(s.text)
